main:
  steps:
  
    # Step 1: Run Cloud Function
    - run_staging_function:
            call: http.get
            args:
                url: "https://us-east1-nsestockanalysis.cloudfunctions.net/staging-function"
                auth:
                    type: OIDC
                    audience: "https://us-east1-nsestockanalysis.cloudfunctions.net/staging-function"
            result: function_result
            next: run_pyspark


    # Step 2: Run PySpark Routine in BigQuery
    - run_pyspark:
            call: googleapis.bigquery.v2.jobs.query
            args:
                projectId: "nsestockanalysis"
                body:
                    query: "CALL nsestockanalysis.stock_dataset.pyspark_transformation();"
                    useLegacySql: false
            result: pyspark_result
            next: delay
    - delay:
        call: sys.sleep
        args:
            seconds: 240
        next: run_sql_merge

    # Step 3: Run SQL Query (mergequeries)
    - run_sql_merge:
        call: googleapis.bigquery.v2.jobs.insert
        args:
          projectId: "nsestockanalysis"
          body:
            configuration:
              query:
                query: |
                  -- First MERGE statement
                  MERGE INTO nsestockanalysis.stock_dataset.fact_stock_data AS target
                  USING (
                      SELECT 
                          symbol, 
                          CAST(date AS DATE) AS date,  
                          previousClose, 
                          open, 
                          close, 
                          buyQty, 
                          sellQty, 
                          trade_volume
                      FROM nsestockanalysis.stock_dataset.stock_data_staging
                  ) AS source
                  ON target.symbol = source.symbol AND target.date = source.date
                  WHEN MATCHED THEN
                    UPDATE SET
                      target.previousClose = source.previousClose,
                      target.open = source.open,
                      target.close = source.close,
                      target.buyQty = source.buyQty,
                      target.sellQty = source.sellQty,
                      target.trade_volume = source.trade_volume
                  WHEN NOT MATCHED THEN
                    INSERT (symbol, date, previousClose, open, close, buyQty, sellQty, trade_volume)
                    VALUES (source.symbol, source.date, source.previousClose, source.open, source.close, source.buyQty, source.sellQty, source.trade_volume);

                 
                  -- Second MERGE statement
                  MERGE INTO nsestockanalysis.stock_dataset.dim_company AS target
                  USING nsestockanalysis.stock_dataset.company_staging AS source
                  ON target.symbol = source.symbol
                  WHEN MATCHED THEN
                    UPDATE SET
                      target.companyName = source.companyName,
                      target.industry = source.industry
                  WHEN NOT MATCHED THEN
                    INSERT (symbol, companyName, industry)
                    VALUES (source.symbol, source.companyName, source.industry);
                useLegacySql: false
        result: merge_result
        next: run_sql_merge_2
#Step 4: Load DTM tables
    - run_sql_merge_2:
        call: googleapis.bigquery.v2.jobs.insert
        args:
          projectId: "nsestockanalysis"
          body:
            configuration:
              query:
                query: |
                    TRUNCATE TABLE nsestockanalysis.stock_dataset.price_change_table;

                    INSERT INTO nsestockanalysis.stock_dataset.price_change_table
                    SELECT
                        symbol,
                        close,
                        ROUND(SAFE_DIVIDE((close - previousClose), previousClose) * 100, 3) AS percent_change_1d,
                        ROUND(SAFE_DIVIDE(close - close_1w, close_1w) * 100, 3) AS percent_change_1w,
                        ROUND(SAFE_DIVIDE(close - close_1m, close_1m) * 100, 3) AS percent_change_1m
                    FROM (
                        SELECT
                            curr.symbol,
                            curr.date,
                            curr.close,
                            curr.previousClose,
                            prev_week.close AS close_1w,
                            prev_month.close AS close_1m
                        FROM nsestockanalysis.stock_dataset.fact_stock_data curr
                        LEFT JOIN nsestockanalysis.stock_dataset.fact_stock_data prev_week
                            ON curr.symbol = prev_week.symbol
                            AND prev_week.date = DATE_SUB(curr.date, INTERVAL 7 DAY)
                        LEFT JOIN nsestockanalysis.stock_dataset.fact_stock_data prev_month
                            ON curr.symbol = prev_month.symbol
                            AND prev_month.date = DATE_SUB(curr.date, INTERVAL 30 DAY)
                        WHERE curr.date = (SELECT MAX(date) FROM nsestockanalysis.stock_dataset.fact_stock_data)
                    );

                    TRUNCATE TABLE nsestockanalysis.stock_dataset.buy_sell_table;

                    INSERT INTO nsestockanalysis.stock_dataset.buy_sell_table
                    SELECT
                        symbol,
                        ROUND(SAFE_DIVIDE(buyQty, sellQty), 2) AS buy_sell_ratio_1d,
                        ROUND(SAFE_DIVIDE(buyQty_1w, sellQty_1w), 2) AS buy_sell_ratio_1w,
                        ROUND(SAFE_DIVIDE(buyQty_1m, sellQty_1m), 2) AS buy_sell_ratio_1m
                    FROM (
                        SELECT
                            curr.symbol,
                            curr.date,
                            curr.buyQty,
                            curr.sellQty,
                            prev_week.buyQty AS buyQty_1w,
                            prev_week.sellQty AS sellQty_1w,
                            prev_month.buyQty AS buyQty_1m,
                            prev_month.sellQty AS sellQty_1m
                        FROM nsestockanalysis.stock_dataset.fact_stock_data curr
                        LEFT JOIN nsestockanalysis.stock_dataset.fact_stock_data prev_week
                            ON curr.symbol = prev_week.symbol
                            AND prev_week.date = DATE_SUB(curr.date, INTERVAL 7 DAY)
                        LEFT JOIN nsestockanalysis.stock_dataset.fact_stock_data prev_month
                            ON curr.symbol = prev_month.symbol
                            AND prev_month.date = DATE_SUB(curr.date, INTERVAL 30 DAY)
                        WHERE curr.date = (SELECT MAX(date) FROM nsestockanalysis.stock_dataset.fact_stock_data)
                    );


                useLegacySql: false
        result: merge_result
        next: run_raw_archive
    # Step 5: Run raw to archive         
    - run_raw_archive:
            call: http.post
            args:
                url: "https://us-east1-nsestockanalysis.cloudfunctions.net/raw-to-archive"
                auth:
                    type: OIDC
                    audience: "https://us-east1-nsestockanalysis.cloudfunctions.net/raw-to-archive"
            result: archive_result
            next: end_workflow

    # Stop workflow execution after success
    - end_workflow:
        return: 
